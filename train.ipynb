{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda\n",
      "epchs:0~9 train_loss: 1.706, train_acc: 0.495, train_times: 0.480s test_loss: 1.759, test_acc: 0.403, test_times: 0.003s\n",
      "epchs:10~19 train_loss: 1.330, train_acc: 0.734, train_times: 0.278s test_loss: 1.390, test_acc: 0.654, test_times: 0.002s\n",
      "epchs:20~29 train_loss: 1.086, train_acc: 0.799, train_times: 0.256s test_loss: 1.134, test_acc: 0.732, test_times: 0.002s\n",
      "epchs:30~39 train_loss: 0.885, train_acc: 0.826, train_times: 0.195s test_loss: 0.981, test_acc: 0.793, test_times: 0.001s\n",
      "epchs:40~49 train_loss: 0.872, train_acc: 0.870, train_times: 0.195s test_loss: 0.874, test_acc: 0.832, test_times: 0.002s\n",
      "epchs:50~59 train_loss: 0.726, train_acc: 0.891, train_times: 0.262s test_loss: 0.798, test_acc: 0.834, test_times: 0.001s\n",
      "epchs:60~69 train_loss: 0.724, train_acc: 0.875, train_times: 0.199s test_loss: 0.746, test_acc: 0.843, test_times: 0.002s\n",
      "epchs:70~79 train_loss: 0.688, train_acc: 0.859, train_times: 0.189s test_loss: 0.707, test_acc: 0.857, test_times: 0.001s\n",
      "epchs:80~89 train_loss: 0.743, train_acc: 0.870, train_times: 0.180s test_loss: 0.683, test_acc: 0.852, test_times: 0.002s\n",
      "epchs:90~99 train_loss: 0.634, train_acc: 0.864, train_times: 0.178s test_loss: 0.673, test_acc: 0.851, test_times: 0.002s\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from models import GCN\n",
    "from sampler import Sampler_FastGCN, Sampler_ASGCN\n",
    "from utils import load_data, get_batches, accuracy\n",
    "from utils import sparse_mx_to_torch_sparse_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = 'cora'\n",
    "model = 'Fast'\n",
    "test_gap = 10\n",
    "hidden = 16\n",
    "fastmode = False\n",
    "seed = 123\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "dropout = 0.0\n",
    "batchsize = 512\n",
    "\n",
    "def train(train_ind, train_labels, batch_size, train_times):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(train_times):\n",
    "        for batch_inds, batch_labels in get_batches(train_ind,\n",
    "                                                    train_labels,\n",
    "                                                    batch_size):\n",
    "            sampled_feats, sampled_adjs, var_loss = model.sampling(\n",
    "                batch_inds)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(sampled_feats, sampled_adjs)\n",
    "            loss_train = loss_fn(output, batch_labels) + 0.5 * var_loss\n",
    "            acc_train = accuracy(output, batch_labels)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "    # just return the train loss of the last train epoch\n",
    "    return loss_train.item(), acc_train.item(), time.time() - t\n",
    "\n",
    "\n",
    "def test(test_adj, test_feats, test_labels, epoch):\n",
    "    t = time.time()\n",
    "    model.eval()\n",
    "    outputs = model(test_feats, test_adj)\n",
    "    loss_test = loss_fn(outputs, test_labels)\n",
    "    acc_test = accuracy(outputs, test_labels)\n",
    "\n",
    "    return loss_test.item(), acc_test.item(), time.time() - t\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "adj, features, adj_train, train_features, y_train, y_test, test_index = \\\n",
    "    load_data(dataset)\n",
    "\n",
    "layer_sizes = [1024, 1024]\n",
    "input_dim = features.shape[1]\n",
    "train_nums = adj_train.shape[0]\n",
    "test_gap = test_gap\n",
    "nclass = y_train.shape[1]\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"use cuda\")\n",
    "\n",
    "# data for train and test\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "train_features = torch.FloatTensor(train_features).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device).max(1)[1]\n",
    "\n",
    "test_adj = [adj, adj[test_index, :]]\n",
    "test_feats = features\n",
    "test_labels = y_test\n",
    "test_adj = [sparse_mx_to_torch_sparse_tensor(cur_adj).to(device)\n",
    "            for cur_adj in test_adj]\n",
    "test_labels = torch.LongTensor(test_labels).to(device).max(1)[1]\n",
    "\n",
    "# init the sampler\n",
    "\n",
    "sampler = Sampler_FastGCN(None, train_features, adj_train,\n",
    "                                input_dim=input_dim,\n",
    "                                layer_sizes=layer_sizes,\n",
    "                                device=device)\n",
    "\n",
    "\n",
    "\n",
    "# init model, optimizer and loss function\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=nclass,\n",
    "            dropout=dropout,\n",
    "            sampler=sampler).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                        lr=lr, weight_decay=weight_decay)\n",
    "loss_fn = F.nll_loss\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# train and test\n",
    "for epochs in range(0, epochs // test_gap):\n",
    "    train_loss, train_acc, train_time = train(np.arange(train_nums),\n",
    "                                                y_train,\n",
    "                                                batchsize,\n",
    "                                                test_gap)\n",
    "    test_loss, test_acc, test_time = test(test_adj,\n",
    "                                            test_feats,\n",
    "                                            test_labels,\n",
    "                                            epochs)\n",
    "    print(f\"epchs:{epochs * test_gap}~{(epochs + 1) * test_gap - 1} \"\n",
    "            f\"train_loss: {train_loss:.3f}, \"\n",
    "            f\"train_acc: {train_acc:.3f}, \"\n",
    "            f\"train_times: {train_time:.3f}s \"\n",
    "            f\"test_loss: {test_loss:.3f}, \"\n",
    "            f\"test_acc: {test_acc:.3f}, \"\n",
    "            f\"test_times: {test_time:.3f}s\")\n",
    "\n",
    "torch.save(model.state_dict(), \"fastGCN.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nums = adj_train.shape[0]\n",
    "train_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from models import GCN\n",
    "from sampler import Sampler_FastGCN, Sampler_ASGCN\n",
    "from utils import load_data, get_batches, accuracy\n",
    "from utils import sparse_mx_to_torch_sparse_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = 'cora'\n",
    "model = 'Fast'\n",
    "test_gap = 10\n",
    "hidden = 16\n",
    "fastmode = False\n",
    "seed = 123\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "dropout = 0.0\n",
    "batchsize = 512\n",
    "\n",
    "def train(train_ind, train_labels, batch_size, train_times):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(train_times):\n",
    "        for batch_inds, batch_labels in get_batches(train_ind,\n",
    "                                                    train_labels,\n",
    "                                                    batch_size):\n",
    "            sampled_feats, sampled_adjs, var_loss = model.sampling(\n",
    "                batch_inds)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(sampled_feats, sampled_adjs)\n",
    "            loss_train = loss_fn(output, batch_labels) + 0.5 * var_loss\n",
    "            acc_train = accuracy(output, batch_labels)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "    # just return the train loss of the last train epoch\n",
    "    return loss_train.item(), acc_train.item(), time.time() - t\n",
    "\n",
    "\n",
    "def test(test_adj, test_feats, test_labels, epoch):\n",
    "    t = time.time()\n",
    "    model.eval()\n",
    "    outputs = model(test_feats, test_adj)\n",
    "    loss_test = loss_fn(outputs, test_labels)\n",
    "    acc_test = accuracy(outputs, test_labels)\n",
    "\n",
    "    return loss_test.item(), acc_test.item(), time.time() - t\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "adj, features, adj_train, train_features, y_train, y_test, test_index = \\\n",
    "    load_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastgcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
